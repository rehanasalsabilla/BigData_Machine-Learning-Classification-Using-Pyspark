{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6897944,"sourceType":"datasetVersion","datasetId":3962399}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2024-10-23T03:44:47.989578Z","iopub.execute_input":"2024-10-23T03:44:47.990271Z","iopub.status.idle":"2024-10-23T03:44:47.997926Z","shell.execute_reply.started":"2024-10-23T03:44:47.990230Z","shell.execute_reply":"2024-10-23T03:44:47.997025Z"}}},{"cell_type":"code","source":"!pip install pyspark","metadata":{"execution":{"iopub.status.busy":"2024-10-23T03:44:47.999431Z","iopub.execute_input":"2024-10-23T03:44:47.999747Z","iopub.status.idle":"2024-10-23T03:44:59.551319Z","shell.execute_reply.started":"2024-10-23T03:44:47.999715Z","shell.execute_reply":"2024-10-23T03:44:59.550293Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!DOCTYPE html>\n<html>\n<head>\n  <link href=\"https://fonts.googleapis.com/css2?family=Poppins:wght@400;700&display=swap\" rel=\"stylesheet\">\n</head>\n<body style=\"font-family: 'Poppins', sans-serif; text-align: center; background-color: #E3F2FD;\">\n\n<h1 style=\"background-color:#28547E; color: white; text-align: center;border-radius: 20px; margin: 20px auto; padding: 15px; \">\n  üìö BIG DATA: Machine Learning Classification Using Pyspark üìö </h1>\n\n<table style=\"font-family: 'Poppins', sans-serif; width: 60%; border-collapse: collapse; margin: 20px auto; overflow: hidden;\">\n  <tr>\n    <th style=\"border: 1px solid #28547E; background-color: #8CB8CA; color: #28547E; font-size: 1.2em; padding: 15px; text-align: center;\">\n      No\n    </th>\n    <th style=\"border: 1px solid #28547E; background-color: #8CB8CA; color: #28547E; font-size: 1.2em; padding: 15px; text-align: center;\">\n      Nama\n    </th>\n    <th style=\"border: 1px solid #28547E; background-color: #8CB8CA; color: #28547E; font-size: 1.2em; padding: 15px; text-align: center;\">\n      NRP\n    </th>\n  </tr>\n  <tr style=\"background-color: #E8F1F4; color: #28547E;\">\n    <td style=\"border: 1px solid #28547E; padding: 15px; text-align: center; font-size: 1.2em;\">\n      1\n    </td>\n    <td style=\"border: 1px solid #28547E; padding: 15px; text-align: center; font-size: 1.2em;\">\n      Mutiara Nurhaliza\n    </td>\n    <td style=\"border: 1px solid #28547E; padding: 15px; text-align: center; font-size: 1.2em;\">\n      5027221010\n    </td>\n  </tr>\n  <tr style=\"background-color: #E8F1F4; color: #28547E;\">\n    <td style=\"border: 1px solid #28547E; padding: 15px; text-align: center; font-size: 1.2em;\">\n      2\n    </td>\n    <td style=\"border: 1px solid #28547E; padding: 15px; text-align: center; font-size: 1.2em;\">\n      Rehana Putri Salsabilla\n    </td>\n    <td style=\"border: 1px solid #28547E; padding: 15px; text-align: center; font-size: 1.2em;\">\n      5027221015\n    </td>\n  </tr>\n  <tr style=\"background-color: #E8F1F4; color: #28547E;\">\n    <td style=\"border: 1px solid #28547E; padding: 15px; text-align: center; font-size: 1.2em;\">\n      3\n    </td>\n    <td style=\"border: 1px solid #28547E; padding: 15px; text-align: center; font-size: 1.2em;\">\n      Salsabila Amalia Harjanto\n    </td>\n    <td style=\"border: 1px solid #28547E; padding: 15px; text-align: center; font-size: 1.2em;\">\n      5027221023\n    </td>\n  </tr>\n</table>\n\n</body>\n</html>\n","metadata":{}},{"cell_type":"markdown","source":"<!DOCTYPE html>\n<html>\n<head>\n  <link href=\"https://fonts.googleapis.com/css2?family=Poppins:wght@400;700&display=swap\" rel=\"stylesheet\">\n</head>\n<body style=\"font-family: 'Poppins', sans-serif; text-align: center; background-color: #E3F2FD;\">\n\n<h2 style=\"background-color:#28547E; color: white; text-align: center;border-radius: 20px; margin: 20px auto; padding: 15px; \">\n  ü§π Understanding The Dataset ü§π </h2>\n\n</body>\n</html>\n","metadata":{}},{"cell_type":"markdown","source":"<!DOCTYPE html>\n<html>\n<head>\n  <link href=\"https://fonts.googleapis.com/css2?family=Poppins:wght@400;700&display=swap\" rel=\"stylesheet\">\n</head>\n<body style=\"font-family: 'Poppins', sans-serif; background-color: #f7f9fc; color: #333; margin: 20px; line-height: 1.6;\">\n\n<div style=\"width: 80%; margin: 0 auto; padding: 20px; background-color: #fff; border-radius: 8px; box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);\">\n  \n  <h2 style=\"color: #1E88E5; font-size: 1.5em; margin-bottom: 10px;\">\n    Deskripsi Dataset\n  </h2>\n  <p>Dataset ini berisi 83.446 data email yang diklasifikasikan sebagai spam atau tidak-spam (ham). Dataset ini merupakan hasil kombinasi dari dua sumber utama, yaitu <strong>2007 TREC Public Spam Corpus</strong> dan <strong>Enron-Spam Dataset</strong>, yang bertujuan untuk membantu dalam pengklasifikasian email spam.</p>\n\n  <h2 style=\"color: #1E88E5; font-size: 1.5em; margin-bottom: 10px;\">\n    Tujuan Klasifikasi Spam\n  </h2>\n  <p>\n    Tujuan utama dari klasifikasi spam adalah untuk membedakan antara email yang sah (ham) dan email yang tidak diinginkan (spam). Klasifikasi ini membantu:\n  </p>\n  <ul style=\"line-height: 1.6;\">\n    <li>Meningkatkan efisiensi komunikasi dengan menyaring email spam sebelum mencapai kotak masuk pengguna.</li>\n    <li>Melindungi pengguna dari konten berbahaya yang sering ditemukan dalam email spam, seperti phising, malware, atau penipuan.</li>\n    <li>Menghemat waktu dan sumber daya dengan mengurangi volume email yang tidak diinginkan.</li>\n    <li>Meningkatkan keamanan siber dengan mendeteksi ancaman yang tersembunyi dalam email spam.</li>\n  </ul>\n  <p>\n    Dengan model klasifikasi spam yang akurat, pengguna dapat lebih fokus pada email yang penting dan relevan, serta menghindari risiko yang ditimbulkan oleh spam.\n  </p>\n\n  <h2 style=\"color: #1E88E5; font-size: 1.5em; margin-bottom: 10px;\">\n    Kolom-Kolom dalam Dataset\n  </h2>\n  <p>\n    <strong>1. label:</strong><br>\n    Berisi label klasifikasi email.<br>\n    '1' menandakan bahwa email diklasifikasikan sebagai <code style=\"background-color: #e8f0fe; padding: 2px 6px; border-radius: 4px;\">spam</code>.<br>\n    '0' menunjukkan bahwa email dianggap sebagai <code style=\"background-color: #e8f0fe; padding: 2px 6px; border-radius: 4px;\">ham</code> (legitimate/tidak-spam).\n  </p>\n  <p>\n    <strong>2. text:</strong><br>\n    Berisi isi pesan email dalam bentuk teks. Kolom ini digunakan untuk memproses dan menganalisis konten email guna menentukan apakah email tersebut termasuk spam atau ham.\n  </p>\n\n  <h2 style=\"color: #1E88E5; font-size: 1.5em; margin-bottom: 10px;\">\n    Sumber Data\n  </h2>\n  <p>\n    Dataset ini berasal dari dua sumber yang terpercaya, yaitu:\n  </p>\n  <p>\n    <strong>1. 2007 TREC Public Spam Corpus</strong><br>\n    Kumpulan data publik dari tahun 2007 yang digunakan untuk riset deteksi spam.<br>\n    Tautan asli: <a href=\"https://plg.uwaterloo.ca/~gvcormac/treccorpus07/\" style=\"color: #1E88E5;\">https://plg.uwaterloo.ca/~gvcormac/treccorpus07/</a><br>\n    Tautan unduhan yang sudah diproses: <a href=\"https://www.kaggle.com/datasets/bayes2003/emails-for-spam-or-ham-classification-trec-2007\" style=\"color: #1E88E5;\">Kaggle - TREC 2007</a>\n  </p>\n  <p>\n    <strong>2. Enron-Spam Dataset</strong><br>\n    Kumpulan data spam yang berasal dari Enron, yang digunakan dalam penelitian akademik untuk pengklasifikasian email.<br>\n    Tautan asli: <a href=\"https://www2.aueb.gr/users/ion/data/enron-spam/\" style=\"color: #1E88E5;\">https://www2.aueb.gr/users/ion/data/enron-spam/</a><br>\n    Tautan unduhan yang sudah diproses: <a href=\"https://github.com/MWiechmann/enron_spam_data/\" style=\"color: #1E88E5;\">GitHub - Enron Spam Data</a>\n  </p>\n\n</div>\n\n</body>\n</html>\n","metadata":{}},{"cell_type":"markdown","source":"<!DOCTYPE html>\n<html>\n<head>\n  <link href=\"https://fonts.googleapis.com/css2?family=Poppins:wght@400;700&display=swap\" rel=\"stylesheet\">\n</head>\n<body style=\"font-family: 'Poppins', sans-serif; text-align: center; background-color: #E3F2FD;\">\n\n<h2 style=\"background-color:#28547E; color: white; text-align: center;border-radius: 20px; margin: 20px auto; padding: 15px; \">\n  üì• Import Library üì• </h2>\n\n</body>\n</html>\n","metadata":{}},{"cell_type":"code","source":"# Import library yang diperlukan\nimport pyspark\nfrom pyspark.sql import SparkSession\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom pyspark.sql.functions import count, when, col\nfrom pyspark.ml.classification import GBTClassifier, RandomForestClassifier, LogisticRegression\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nimport matplotlib.pyplot as plt\nfrom pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T03:44:59.553393Z","iopub.execute_input":"2024-10-23T03:44:59.553721Z","iopub.status.idle":"2024-10-23T03:44:59.561241Z","shell.execute_reply.started":"2024-10-23T03:44:59.553687Z","shell.execute_reply":"2024-10-23T03:44:59.560376Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!DOCTYPE html>\n<html>\n<head>\n  <link href=\"https://fonts.googleapis.com/css2?family=Poppins:wght@400;700&display=swap\" rel=\"stylesheet\">\n</head>\n<body style=\"font-family: 'Poppins', sans-serif; text-align: center; background-color: #E3F2FD;\">\n\n<h2 style=\"background-color:#28547E; color: white; text-align: center;border-radius: 20px; margin: 20px auto; padding: 15px; \">\n  ‚ú® Creating Spark Session ‚ú® </h2>\n\n</body>\n</html>\n","metadata":{}},{"cell_type":"code","source":"# Membuat Spark session\nspark = SparkSession.builder.appName('Email Spam Classification').getOrCreate()\n\n# Define the schema explicitly\nfrom pyspark.sql.types import StructType, StructField, StringType\nschema = StructType([\n    StructField(\"label\", StringType(), True),\n    StructField(\"text\", StringType(), True)\n])\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T03:44:59.562460Z","iopub.execute_input":"2024-10-23T03:44:59.563233Z","iopub.status.idle":"2024-10-23T03:44:59.577402Z","shell.execute_reply.started":"2024-10-23T03:44:59.563199Z","shell.execute_reply":"2024-10-23T03:44:59.576478Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!DOCTYPE html>\n<html>\n<head>\n  <link href=\"https://fonts.googleapis.com/css2?family=Poppins:wght@400;700&display=swap\" rel=\"stylesheet\">\n</head>\n<body style=\"font-family: 'Poppins', sans-serif; text-align: center; background-color: #E3F2FD;\">\n\n<h2 style=\"background-color:#28547E; color: white; text-align: center;border-radius: 20px; margin: 20px auto; padding: 15px; \">\n  üèóÔ∏è Load Dataset üèóÔ∏è </h2>\n\n</body>\n</html>\n","metadata":{}},{"cell_type":"code","source":"# Load dataset\ndf = spark.read.option(\"multiLine\", True).option(\"escape\", '\"').csv('/kaggle/input/combined_data.csv', header=True, schema=schema)\n\n# Menampilkan informasi kolom dan tipe data\ndf.printSchema()\ndf.show(10)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T03:44:59.579819Z","iopub.execute_input":"2024-10-23T03:44:59.580114Z","iopub.status.idle":"2024-10-23T03:44:59.754876Z","shell.execute_reply.started":"2024-10-23T03:44:59.580083Z","shell.execute_reply":"2024-10-23T03:44:59.753821Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!DOCTYPE html>\n<html>\n<head>\n  <link href=\"https://fonts.googleapis.com/css2?family=Poppins:wght@400;700&display=swap\" rel=\"stylesheet\">\n</head>\n<body style=\"font-family: 'Poppins', sans-serif; text-align: center; background-color: #E3F2FD;\">\n\n<h2 style=\"background-color:#28547E; color: white; text-align: center;border-radius: 20px; margin: 20px auto; padding: 15px; \">\n  üî≠ Data Exploration Analysis üî≠ </h2>\n\n</body>\n</html>\n","metadata":{}},{"cell_type":"markdown","source":"### Memeriksa Deskripsi Dataset ","metadata":{}},{"cell_type":"code","source":"df.describe().show()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T03:44:59.755979Z","iopub.execute_input":"2024-10-23T03:44:59.756383Z","iopub.status.idle":"2024-10-23T03:45:02.102300Z","shell.execute_reply.started":"2024-10-23T03:44:59.756338Z","shell.execute_reply":"2024-10-23T03:45:02.101231Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Memeriksa Nilai Yang Hilang","metadata":{}},{"cell_type":"code","source":"missing_values = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\nmissing_values.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T03:45:02.103466Z","iopub.execute_input":"2024-10-23T03:45:02.103895Z","iopub.status.idle":"2024-10-23T03:45:03.320330Z","shell.execute_reply.started":"2024-10-23T03:45:02.103849Z","shell.execute_reply":"2024-10-23T03:45:03.319343Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Jumlah Data Spam dan Ham","metadata":{}},{"cell_type":"code","source":"spam_count = df.filter(df.label == '1').count()  # Spam\nham_count = df.filter(df.label == '0').count()   # Ham\n\nprint(f\"Spam Count: {spam_count}, Ham Count: {ham_count}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-23T03:45:03.321436Z","iopub.execute_input":"2024-10-23T03:45:03.321835Z","iopub.status.idle":"2024-10-23T03:45:05.434146Z","shell.execute_reply.started":"2024-10-23T03:45:03.321799Z","shell.execute_reply":"2024-10-23T03:45:05.433138Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Distribusi Panjang Email Berdasarkan Label","metadata":{}},{"cell_type":"code","source":"# Menghitung panjang setiap email\ndf = df.withColumn('length', pyspark.sql.functions.length(col('text')))\n\n# Menampilkan distribusi panjang teks untuk email Spam dan Ham\ndf.groupBy('label').agg({'length': 'mean'}).show()\n\n# Visualisasi distribusi panjang teks\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndf_pandas = df.select(\"label\", \"length\").toPandas()\n\nplt.figure(figsize=(10,6))\nsns.histplot(data=df_pandas, x='length', hue='label', multiple='stack', bins=50, palette=['red', 'green'])\nplt.title('Distribution of Email Length by Label (Spam vs Ham)')\nplt.xlabel('Length of Email')\nplt.ylabel('Frequency')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T03:45:05.435257Z","iopub.execute_input":"2024-10-23T03:45:05.435771Z","iopub.status.idle":"2024-10-23T03:45:11.309140Z","shell.execute_reply.started":"2024-10-23T03:45:05.435724Z","shell.execute_reply":"2024-10-23T03:45:11.308059Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Distribusi Email Spam dan Ham","metadata":{}},{"cell_type":"code","source":"# Visualisasi distribusi Spam dan Ham\nlabels = ['Spam', 'Ham']\nsizes = [spam_count, ham_count]\nplt.figure(figsize=(6, 4))\nplt.bar(labels, sizes, color=['red', 'green'])\nplt.title('Distribution of Spam and Ham Emails')\nplt.xlabel('Email Type')\nplt.ylabel('Count')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T03:45:11.310404Z","iopub.execute_input":"2024-10-23T03:45:11.310984Z","iopub.status.idle":"2024-10-23T03:45:11.560306Z","shell.execute_reply.started":"2024-10-23T03:45:11.310938Z","shell.execute_reply":"2024-10-23T03:45:11.559427Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Wordcloud","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\n# Mengonversi DataFrame Spark menjadi Pandas DataFrame untuk memudahkan analisis\ndf_pandas = df.toPandas()\n\n# Menggabungkan semua teks spam\nspam_text = \" \".join(text for text in df_pandas[df_pandas[\"label\"] == \"1\"].text)\n\n# Menggabungkan semua teks ham\nham_text = \" \".join(text for text in df_pandas[df_pandas[\"label\"] == \"0\"].text)\n\n# Membuat WordCloud untuk Spam\nspam_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(spam_text)\n\n# Membuat WordCloud untuk Ham\nham_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(ham_text)\n\n# Menampilkan WordCloud untuk Spam\nplt.figure(figsize=(10, 5))\nplt.imshow(spam_wordcloud, interpolation='bilinear')\nplt.title('Word Cloud - Spam Emails')\nplt.axis('off')\nplt.show()\n\n# Menampilkan WordCloud untuk Ham\nplt.figure(figsize=(10, 5))\nplt.imshow(ham_wordcloud, interpolation='bilinear')\nplt.title('Word Cloud - Ham Emails')\nplt.axis('off')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T03:45:11.563396Z","iopub.execute_input":"2024-10-23T03:45:11.563722Z","iopub.status.idle":"2024-10-23T03:46:45.614342Z","shell.execute_reply.started":"2024-10-23T03:45:11.563689Z","shell.execute_reply":"2024-10-23T03:46:45.613399Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!DOCTYPE html>\n<html>\n<head>\n  <link href=\"https://fonts.googleapis.com/css2?family=Poppins:wght@400;700&display=swap\" rel=\"stylesheet\">\n</head>\n<body style=\"font-family: 'Poppins', sans-serif; text-align: center; background-color: #E3F2FD;\">\n\n<h2 style=\"background-color:#28547E; color: white; text-align: center;border-radius: 20px; margin: 20px auto; padding: 15px; \">\n  üìù Data Prepocessing üìù </h2>\n\n</body>\n</html>\n","metadata":{}},{"cell_type":"markdown","source":"<!DOCTYPE html>\n<html>\n<head>\n  <link href=\"https://fonts.googleapis.com/css2?family=Poppins:wght@400;700&display=swap\" rel=\"stylesheet\">\n</head>\n<body style=\"font-family: 'Poppins', sans-serif; background-color: #f7f9fc; color: #333; margin: 20px; line-height: 1.6;\">\n\n<div style=\"width: 80%; margin: 0 auto; padding: 20px; background-color: #fff; border-radius: 8px; box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);\">\n  \n  <h2 style=\"color: #1E88E5; font-size: 1.5em; margin-bottom: 10px;\">\n    1. StringIndexer\n  </h2>\n  <p>Konversi label teks seperti <code style=\"background-color: #e8f0fe; padding: 2px 6px; border-radius: 4px;\">\"spam\"</code> dan <code style=\"background-color: #e8f0fe; padding: 2px 6px; border-radius: 4px;\">\"ham\"</code> menjadi nilai numerik agar model machine learning bisa memproses data dengan baik.</p>\n  <p><strong>Alasan:</strong> Model machine learning bekerja dengan data numerik, sehingga label teks harus dikonversi menjadi nilai numerik agar dapat diolah oleh algoritma.</p>\n\n  <h2 style=\"color: #1E88E5; font-size: 1.5em; margin-bottom: 10px;\">\n    2. Tokenizer\n  </h2>\n  <p>Memecah teks menjadi kata-kata individual (token) untuk persiapan ekstraksi fitur.</p>\n  <p><strong>Alasan:</strong> Teks mentah tidak dapat langsung digunakan oleh model. Tokenisasi diperlukan untuk mengubah kalimat menjadi kata-kata yang lebih kecil, sehingga setiap kata dapat diproses sebagai fitur.</p>\n\n  <h2 style=\"color: #1E88E5; font-size: 1.5em; margin-bottom: 10px;\">\n    3. StopWordsRemover\n  </h2>\n  <p>Menghapus kata-kata umum yang tidak penting, seperti <code style=\"background-color: #e8f0fe; padding: 2px 6px; border-radius: 4px;\">\"the\"</code> atau <code style=\"background-color: #e8f0fe; padding: 2px 6px; border-radius: 4px;\">\"is\"</code>, untuk fokus pada kata yang lebih bermakna.</p>\n  <p><strong>Alasan:</strong> Kata-kata umum tidak memiliki nilai yang signifikan dalam membedakan antara spam dan ham. Menghapus stop words membantu model untuk lebih fokus pada kata-kata yang lebih informatif.</p>\n\n  <h2 style=\"color: #1E88E5; font-size: 1.5em; margin-bottom: 10px;\">\n    4. HashingTF\n  </h2>\n  <p>Mengubah kata-kata menjadi fitur numerik berdasarkan frekuensinya dalam teks.</p>\n  <p><strong>Alasan:</strong> Menghitung frekuensi kemunculan kata di dalam teks membantu dalam memahami seberapa penting kata tersebut di dalam dokumen. Kata yang sering muncul dalam email spam, misalnya, dapat membantu dalam klasifikasi.</p>\n\n  <h2 style=\"color: #1E88E5; font-size: 1.5em; margin-bottom: 10px;\">\n    5. IDF (Inverse Document Frequency)\n  </h2>\n  <p>Menyesuaikan bobot fitur, memberi nilai lebih tinggi pada kata-kata yang jarang muncul untuk meningkatkan akurasi model.</p>\n  <p><strong>Alasan:</strong> Kata-kata yang muncul terlalu sering di banyak dokumen mungkin kurang bermakna untuk membedakan spam dari ham. IDF mengurangi pengaruh kata yang sering muncul dan memberi bobot lebih besar pada kata-kata yang jarang, namun relevan.</p>\n\n</div>\n\n</body>\n</html>","metadata":{}},{"cell_type":"code","source":"# Konversi label dari string ke numerik menggunakan StringIndexer\nindexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\")\ndf_indexed = indexer.fit(df).transform(df)\n\n# Tokenisasi dan menghapus kata umum (stop words)\ntokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\ndf_indexed = tokenizer.transform(df_indexed)\n\nremover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\ndf_indexed = remover.transform(df_indexed)\n\n# Menggunakan TF-IDF\nhashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\nfeaturizedData = hashingTF.transform(df_indexed)\n\nidf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\nidfModel = idf.fit(featurizedData)\ntfidfData = idfModel.transform(featurizedData)\n\n# Menampilkan data TF-IDF\ntfidfData.show()\ntfidfData.printSchema()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T03:46:45.615611Z","iopub.execute_input":"2024-10-23T03:46:45.616046Z","iopub.status.idle":"2024-10-23T03:47:19.320980Z","shell.execute_reply.started":"2024-10-23T03:46:45.616011Z","shell.execute_reply":"2024-10-23T03:47:19.319753Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!DOCTYPE html>\n<html>\n<head>\n  <link href=\"https://fonts.googleapis.com/css2?family=Poppins:wght@400;700&display=swap\" rel=\"stylesheet\">\n</head>\n<body style=\"font-family: 'Poppins', sans-serif; text-align: center; background-color: #E3F2FD;\">\n\n<h2 style=\"background-color:#28547E; color: white; text-align: center;border-radius: 20px; margin: 20px auto; padding: 15px; \">\n  ‚úÇÔ∏è Split Dataset ‚úÇÔ∏è </h2>\n\n</body>\n</html>\n","metadata":{}},{"cell_type":"code","source":"# Membagi dataset menjadi data train dan test\ntrain_data, test_data = tfidfData.randomSplit([0.8, 0.2], seed=42)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T03:47:19.323413Z","iopub.execute_input":"2024-10-23T03:47:19.323831Z","iopub.status.idle":"2024-10-23T03:47:19.349467Z","shell.execute_reply.started":"2024-10-23T03:47:19.323785Z","shell.execute_reply":"2024-10-23T03:47:19.348461Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\n\n# Mengambil kolom label dari train_data dan test_data\ntrain_labels = train_data.select('indexedLabel').toPandas()\ntest_labels = test_data.select('indexedLabel').toPandas()\n\n# Menghitung distribusi label (Ham = 0, Spam = 1)\ntrain_label_counts = train_labels['indexedLabel'].value_counts()\ntest_label_counts = test_labels['indexedLabel'].value_counts()\n\n# Mendefinisikan label untuk pie chart (Ham dan Spam)\nlabels = {0: 'Ham', 1: 'Spam'}\n\n# Visualisasi distribusi dengan pie chart\nplt.figure(figsize=(10, 5))\n\n# Pie chart untuk training set\nplt.subplot(1, 2, 1)\nplt.title(\"Training Set\")\nplt.pie(train_label_counts, labels=[labels[i] for i in train_label_counts.index], autopct=\"%.2f%%\", colors=['blue', 'grey'])\n\n# Pie chart untuk testing set\nplt.subplot(1, 2, 2)\nplt.title(\"Testing Set\")\nplt.pie(test_label_counts, labels=[labels[i] for i in test_label_counts.index], autopct=\"%.2f%%\", colors=['blue', 'grey'])\n\n# Menampilkan plot\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T03:47:19.350619Z","iopub.execute_input":"2024-10-23T03:47:19.351539Z","iopub.status.idle":"2024-10-23T03:48:40.240395Z","shell.execute_reply.started":"2024-10-23T03:47:19.351474Z","shell.execute_reply":"2024-10-23T03:48:40.239178Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!DOCTYPE html>\n<html>\n<head>\n  <link href=\"https://fonts.googleapis.com/css2?family=Poppins:wght@400;700&display=swap\" rel=\"stylesheet\">\n</head>\n<body style=\"font-family: 'Poppins', sans-serif; text-align: center; background-color: #E3F2FD;\">\n\n<h2 style=\"background-color:#28547E; color: white; text-align: center;border-radius: 20px; margin: 20px auto; padding: 15px; \">\n  ‚öôÔ∏è Training Data ‚öôÔ∏è </h2>\n\n</body>\n</html>\n","metadata":{}},{"cell_type":"markdown","source":"<!DOCTYPE html>\n<html>\n<head>\n  <link href=\"https://fonts.googleapis.com/css2?family=Poppins:wght@400;700&display=swap\" rel=\"stylesheet\">\n</head>\n<body style=\"font-family: 'Poppins', sans-serif; background-color: #f7f9fc; color: #333; margin: 20px; line-height: 1.6;\">\n\n<div style=\"width: 80%; margin: 0 auto; padding: 20px; background-color: #fff; border-radius: 8px; box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);\">\n  \n  <h2 style=\"color: #1E88E5; font-size: 1.5em; margin-bottom: 10px;\">\n    Evaluasi Model: Accuracy, RMSE, dan MAE\n  </h2>\n  <p>Evaluasi model adalah langkah penting dalam menilai kinerja algoritma. Ada berbagai metrik yang dapat digunakan untuk mengukur performa model, termasuk <strong>Accuracy</strong>, <strong>RMSE (Root Mean Squared Error)</strong>, dan <strong>MAE (Mean Absolute Error)</strong>. Berikut adalah penjelasan dari masing-masing metrik:</p>\n\n  <h2 style=\"color: #1E88E5; font-size: 1.5em; margin-bottom: 10px;\">\n    Accuracy\n  </h2>\n  <p>\n    <strong>Accuracy:</strong><br>\n    Accuracy mengukur seberapa sering model membuat prediksi yang benar dari total keseluruhan prediksi. Nilai ini sangat berguna untuk klasifikasi, khususnya ketika kelas-kelas seimbang.<br>\n    <strong>Rumus:</strong><br>\n    <code style=\"background-color: #e8f0fe; padding: 2px 6px; border-radius: 4px;\">Accuracy = (Jumlah Prediksi Benar) / (Total Prediksi)</code><br>\n    Namun, accuracy bisa menjadi kurang representatif jika dataset memiliki ketidakseimbangan kelas yang besar.\n  </p>\n\n  <h2 style=\"color: #1E88E5; font-size: 1.5em; margin-bottom: 10px;\">\n    RMSE (Root Mean Squared Error)\n  </h2>\n  <p>\n    <strong>RMSE:</strong><br>\n    RMSE mengukur rata-rata dari kuadrat perbedaan antara nilai yang diprediksi dan nilai aktual. Metrik ini memberikan penalti lebih besar pada kesalahan prediksi yang lebih besar karena menggunakan kuadrat dalam perhitungannya.<br>\n    <strong>Rumus:</strong><br>\n    <code style=\"background-color: #e8f0fe; padding: 2px 6px; border-radius: 4px;\">RMSE = sqrt((1/n) Œ£(y_pred - y_actual)^2)</code><br>\n    RMSE sangat berguna ketika kita ingin memberi bobot lebih besar terhadap kesalahan besar dan fokus pada prediksi yang lebih akurat.\n  </p>\n\n  <h2 style=\"color: #1E88E5; font-size: 1.5em; margin-bottom: 10px;\">\n    MAE (Mean Absolute Error)\n  </h2>\n  <p>\n    <strong>MAE:</strong><br>\n    MAE mengukur rata-rata dari nilai absolut kesalahan antara prediksi dan nilai aktual. Metrik ini memberikan ukuran rata-rata kesalahan yang tidak bergantung pada nilai ekstrem (outlier) karena tidak menggunakan kuadrat.<br>\n    <strong>Rumus:</strong><br>\n    <code style=\"background-color: #e8f0fe; padding: 2px 6px; border-radius: 4px;\">MAE = (1/n) Œ£|y_pred - y_actual|</code><br>\n    MAE cocok digunakan jika Anda ingin mengevaluasi kesalahan prediksi secara rata-rata tanpa memberi penalti lebih pada outlier.\n  </p>\n\n</div>\n\n</body>\n</html>","metadata":{}},{"cell_type":"markdown","source":"### Logistic Regression","metadata":{}},{"cell_type":"code","source":"from pyspark.ml.evaluation import RegressionEvaluator\n\n# Logistic Regression\nlr = LogisticRegression(featuresCol=\"features\", labelCol=\"indexedLabel\")\n\n# Melatih model Logistic Regression\nlr_model = lr.fit(train_data)\n\n# Memprediksi data test\nlr_predictions = lr_model.transform(test_data)\n\n# Evaluasi Logistic Regression untuk akurasi\nlr_evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\nlr_accuracy = lr_evaluator.evaluate(lr_predictions)\nprint(f\"Logistic Regression Accuracy: {lr_accuracy:.2f}\")\n\n# Evaluasi RMSE dan MAE\nrmse_evaluator = RegressionEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"rmse\")\nlr_rmse = rmse_evaluator.evaluate(lr_predictions)\nprint(f\"Logistic Regression RMSE: {lr_rmse:.2f}\")\n\nmae_evaluator = RegressionEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"mae\")\nlr_mae = mae_evaluator.evaluate(lr_predictions)\nprint(f\"Logistic Regression MAE: {lr_mae:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-23T03:48:40.245847Z","iopub.execute_input":"2024-10-23T03:48:40.248966Z","iopub.status.idle":"2024-10-23T03:52:08.140905Z","shell.execute_reply.started":"2024-10-23T03:48:40.248897Z","shell.execute_reply":"2024-10-23T03:52:08.139717Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"from pyspark.ml.evaluation import RegressionEvaluator\n\n# Random Forest Classifier\nrf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"features\", numTrees=10)\n\n# Melatih model Random Forest\nrf_model = rf.fit(train_data)\n\n# Memprediksi data test\nrf_predictions = rf_model.transform(test_data)\n\n# Evaluasi Random Forest untuk akurasi\nrf_evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\nrf_accuracy = rf_evaluator.evaluate(rf_predictions)\nprint(f\"Random Forest Accuracy: {rf_accuracy:.2f}\")\n\n# Evaluasi RMSE dan MAE\nrmse_evaluator = RegressionEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"rmse\")\nrf_rmse = rmse_evaluator.evaluate(rf_predictions)\nprint(f\"Random Forest RMSE: {rf_rmse:.2f}\")\n\nmae_evaluator = RegressionEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"mae\")\nrf_mae = mae_evaluator.evaluate(rf_predictions)\nprint(f\"Random Forest MAE: {rf_mae:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T03:52:08.142571Z","iopub.execute_input":"2024-10-23T03:52:08.142963Z","iopub.status.idle":"2024-10-23T03:57:31.127586Z","shell.execute_reply.started":"2024-10-23T03:52:08.142920Z","shell.execute_reply":"2024-10-23T03:57:31.126566Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Gradient Boosted Tree","metadata":{}},{"cell_type":"code","source":"from pyspark.ml.evaluation import RegressionEvaluator\n\n# Gradient Boosted Trees\ngbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"features\", maxIter=10)\n\n# Melatih model Gradient Boosted Trees\ngbt_model = gbt.fit(train_data)\n\n# Memprediksi data test\ngbt_predictions = gbt_model.transform(test_data)\n\n# Evaluasi Gradient Boosted Trees untuk akurasi\ngbt_evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\ngbt_accuracy = gbt_evaluator.evaluate(gbt_predictions)\nprint(f\"Gradient Boosted Trees Accuracy: {gbt_accuracy:.2f}\")\n\n# Evaluasi RMSE dan MAE\nrmse_evaluator = RegressionEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"rmse\")\ngbt_rmse = rmse_evaluator.evaluate(gbt_predictions)\nprint(f\"Gradient Boosted Trees RMSE: {gbt_rmse:.2f}\")\n\nmae_evaluator = RegressionEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"mae\")\ngbt_mae = mae_evaluator.evaluate(gbt_predictions)\nprint(f\"Gradient Boosted Trees MAE: {gbt_mae:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T03:57:31.128933Z","iopub.execute_input":"2024-10-23T03:57:31.129373Z","iopub.status.idle":"2024-10-23T04:13:42.971358Z","shell.execute_reply.started":"2024-10-23T03:57:31.129324Z","shell.execute_reply":"2024-10-23T04:13:42.968951Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!DOCTYPE html>\n<html>\n<head>\n  <link href=\"https://fonts.googleapis.com/css2?family=Poppins:wght@400;700&display=swap\" rel=\"stylesheet\">\n</head>\n<body style=\"font-family: 'Poppins', sans-serif; text-align: center; background-color: #E3F2FD;\">\n\n<h2 style=\"background-color:#28547E; color: white; text-align: center;border-radius: 20px; margin: 20px auto; padding: 15px; \">\n  üìä Evaluation üìä </h2>\n\n</body>\n</html>\n","metadata":{}},{"cell_type":"markdown","source":"### Confusion Matrix dan Classification Report untuk Logistic Regression","metadata":{}},{"cell_type":"code","source":"\n# Mengambil prediksi dan label asli dari PySpark DataFrame\nlr_pred = lr_predictions.select('prediction').collect()\nlr_true = lr_predictions.select('indexedLabel').collect()\n\n# Menghitung confusion matrix\nlr_cm = confusion_matrix(lr_true, lr_pred)\n\n# Membuat confusion matrix menjadi DataFrame untuk visualisasi\ncm_df = pd.DataFrame(lr_cm, index=['Actual Ham', 'Actual Spam'], columns=['Predicted Ham', 'Predicted Spam'])\n\n# Menampilkan confusion matrix\nprint(\"\\nLogistic Regression Confusion Matrix:\")\nprint(cm_df)\n\n# Visualisasi confusion matrix dengan seaborn\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm_df, annot=True, fmt='g', cmap='Blues', linewidths=1, linecolor='black')\nplt.title('Confusion Matrix - Logistic Regression')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.tight_layout()\nplt.show()\n\n# Menampilkan classification report\nprint(\"\\nLogistic Regression Classification Report:\")\nprint(classification_report(lr_true, lr_pred, target_names=['Ham', 'Spam']))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T04:13:42.972999Z","iopub.execute_input":"2024-10-23T04:13:42.974946Z","iopub.status.idle":"2024-10-23T04:14:58.593517Z","shell.execute_reply.started":"2024-10-23T04:13:42.974898Z","shell.execute_reply":"2024-10-23T04:14:58.592562Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!DOCTYPE html>\n<html>\n<head>\n  <link href=\"https://fonts.googleapis.com/css2?family=Poppins:wght@400;700&display=swap\" rel=\"stylesheet\">\n</head>\n<body style=\"font-family: 'Poppins', sans-serif; background-color: #f7f9fc; color: #333; margin: 20px; line-height: 1.6;\">\n\n<div style=\"width: 80%; margin: 0 auto; padding: 20px; background-color: #fff; border-radius: 8px; box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);\">\n  \n  <h2 style=\"color: #1E88E5; font-size: 1.5em; margin-bottom: 10px;\">\n    Keterangan\n  </h2>\n  <p>\n    <strong>Precision, Recall, dan F1-Score:</strong><br>\n    Hasil precision, recall, dan f1-score untuk kelas \"Ham\" dan \"Spam\" hampir sama, sekitar 0.96-0.97.<br>\n    Akurasi keseluruhan mencapai 0.97, menunjukkan bahwa model ini sangat baik dalam membedakan antara \"Ham\" dan \"Spam\".\n  </p>\n  \n  <h2 style=\"color: #1E88E5; font-size: 1.5em; margin-bottom: 10px;\">\n    Analisis\n  </h2>\n  <p>\n    Logistic Regression adalah model linear, yang bekerja dengan baik ketika data dapat dipisahkan secara linear. Dalam hal ini, data yang digunakan mungkin memiliki pola yang cukup linear sehingga Logistic Regression dapat menghasilkan performa yang sangat baik.<br>\n    Hasil yang tinggi pada precision dan recall untuk kedua kelas menunjukkan bahwa model ini seimbang dalam mendeteksi \"Ham\" dan \"Spam\" secara akurat.\n  </p>\n  \n  <h2 style=\"color: #1E88E5; font-size: 1.5em; margin-bottom: 10px;\">\n    Alasan Performa\n  </h2>\n  <p>\n    Logistic Regression memprediksi probabilitas berbasis fungsi logistik, dan jika data tidak memiliki banyak hubungan kompleks atau non-linear, maka model ini sangat efektif.<br>\n    Jika fitur-fitur yang digunakan sudah dipilih atau diubah dengan baik (misalnya melalui normalisasi atau seleksi fitur), maka Logistic Regression dapat menghasilkan performa yang optimal.\n  </p>\n\n</div>\n\n</body>\n</html>\n","metadata":{}},{"cell_type":"markdown","source":"### Confusion Matrix dan Classification Report for Random Forest","metadata":{}},{"cell_type":"code","source":"\n# Mengambil prediksi dan label asli dari PySpark DataFrame untuk Random Forest\nrf_pred = rf_predictions.select('prediction').collect()\nrf_true = rf_predictions.select('indexedLabel').collect()\n\n# Menghitung confusion matrix untuk Random Forest\nrf_cm = confusion_matrix(rf_true, rf_pred)\n\n# Membuat confusion matrix menjadi DataFrame untuk visualisasi\nrf_cm_df = pd.DataFrame(rf_cm, index=['Actual Ham', 'Actual Spam'], columns=['Predicted Ham', 'Predicted Spam'])\n\n# Menampilkan confusion matrix dalam bentuk teks\nprint(\"\\nRandom Forest Confusion Matrix:\")\nprint(rf_cm_df)\n\n# Visualisasi confusion matrix dengan seaborn\nplt.figure(figsize=(6, 4))\nsns.heatmap(rf_cm_df, annot=True, fmt='g', cmap='Blues', linewidths=1, linecolor='black')\nplt.title('Confusion Matrix - Random Forest')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.tight_layout()\nplt.show()\n\n# Menampilkan classification report untuk Random Forest\nprint(\"\\nRandom Forest Classification Report:\")\nprint(classification_report(rf_true, rf_pred, target_names=['Ham', 'Spam']))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T04:14:58.594672Z","iopub.execute_input":"2024-10-23T04:14:58.595019Z","iopub.status.idle":"2024-10-23T04:16:14.000483Z","shell.execute_reply.started":"2024-10-23T04:14:58.594982Z","shell.execute_reply":"2024-10-23T04:16:13.999335Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!DOCTYPE html>\n<html>\n<head>\n  <link href=\"https://fonts.googleapis.com/css2?family=Poppins:wght@400;700&display=swap\" rel=\"stylesheet\">\n</head>\n<body style=\"font-family: 'Poppins', sans-serif; background-color: #f7f9fc; color: #333; margin: 20px; line-height: 1.6;\">\n\n<div style=\"width: 80%; margin: 0 auto; padding: 20px; background-color: #fff; border-radius: 8px; box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);\">\n  \n  <h2 style=\"color: #1E88E5; font-size: 1.5em; margin-bottom: 10px;\">\n    Keterangan\n  </h2>\n  <p>\n    <strong>Precision, Recall, dan F1-Score:</strong><br>\n    Kelas \"Ham\" memiliki precision 0.74 dan recall 0.97, menunjukkan bahwa model ini dapat mendeteksi sebagian besar pesan \"Ham\" dengan baik, tetapi sering salah mengklasifikasikan beberapa pesan \"Spam\" sebagai \"Ham\".<br>\n    Kelas \"Spam\" memiliki precision 0.95 tetapi recall rendah (0.61), yang berarti banyak pesan \"Spam\" tidak terdeteksi dengan baik.<br>\n    Akurasi keseluruhan sebesar 0.81, yang lebih rendah dibandingkan dengan Logistic Regression.\n  </p>\n  \n  <h2 style=\"color: #1E88E5; font-size: 1.5em; margin-bottom: 10px;\">\n    Analisis\n  </h2>\n  <p>\n    Random Forest terdiri dari banyak decision tree, dan performanya dapat dipengaruhi oleh distribusi data dan parameter seperti jumlah pohon, kedalaman maksimum, dll.<br>\n    Dalam kasus ini, mungkin ada ketidakseimbangan atau noise dalam data yang mempengaruhi kemampuannya untuk mendeteksi \"Spam\" dengan baik.\n  </p>\n  \n  <h2 style=\"color: #1E88E5; font-size: 1.5em; margin-bottom: 10px;\">\n    Alasan Performa\n  </h2>\n  <p>\n    Model ini mungkin terlalu sensitif terhadap salah satu kelas, sehingga tidak dapat menangkap pola yang lebih halus dari kelas \"Spam\".<br>\n    Pengaturan parameter seperti jumlah pohon atau kedalaman pohon bisa kurang optimal, atau data memiliki beberapa fitur yang lebih relevan untuk Logistic Regression.\n  </p>\n\n</div>\n\n</body>\n</html>\n","metadata":{}},{"cell_type":"markdown","source":"### Confusion Matrix dan Classification Report for Gradient Boosted Trees","metadata":{}},{"cell_type":"code","source":"\n# Mengambil prediksi dan label asli dari PySpark DataFrame untuk Gradient Boosted Trees\ngbt_pred = gbt_predictions.select('prediction').collect()\ngbt_true = gbt_predictions.select('indexedLabel').collect()\n\n# Menghitung confusion matrix untuk Gradient Boosted Trees\ngbt_cm = confusion_matrix(gbt_true, gbt_pred)\n\n# Membuat confusion matrix menjadi DataFrame untuk visualisasi\ngbt_cm_df = pd.DataFrame(gbt_cm, index=['Actual Ham', 'Actual Spam'], columns=['Predicted Ham', 'Predicted Spam'])\n\n# Menampilkan confusion matrix dalam bentuk teks\nprint(\"\\nGradient Boosted Trees Confusion Matrix:\")\nprint(gbt_cm_df)\n\n# Visualisasi confusion matrix dengan seaborn\nplt.figure(figsize=(6, 4))\nsns.heatmap(gbt_cm_df, annot=True, fmt='g', cmap='Blues', linewidths=1, linecolor='black')\nplt.title('Confusion Matrix - Gradient Boosted Trees')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.tight_layout()\nplt.show()\n\n# Menampilkan classification report untuk Gradient Boosted Trees\nprint(\"\\nGradient Boosted Trees Classification Report:\")\nprint(classification_report(gbt_true, gbt_pred, target_names=['Ham', 'Spam']))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T04:16:14.001872Z","iopub.execute_input":"2024-10-23T04:16:14.002173Z","iopub.status.idle":"2024-10-23T04:17:28.965880Z","shell.execute_reply.started":"2024-10-23T04:16:14.002141Z","shell.execute_reply":"2024-10-23T04:17:28.964737Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!DOCTYPE html>\n<html>\n<head>\n  <link href=\"https://fonts.googleapis.com/css2?family=Poppins:wght@400;700&display=swap\" rel=\"stylesheet\">\n</head>\n<body style=\"font-family: 'Poppins', sans-serif; background-color: #f7f9fc; color: #333; margin: 20px; line-height: 1.6;\">\n\n<div style=\"width: 80%; margin: 0 auto; padding: 20px; background-color: #fff; border-radius: 8px; box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);\">\n  \n  <h2 style=\"color: #1E88E5; font-size: 1.5em; margin-bottom: 10px;\">\n    Keterangan\n  </h2>\n  <p>\n    <strong>Precision, Recall, dan F1-Score:</strong><br>\n    Kelas \"Ham\" memiliki precision 0.86 dan recall 0.97, yang berarti performa hampir sama dengan Logistic Regression dalam mendeteksi \"Ham\".<br>\n    Kelas \"Spam\" memiliki precision tinggi (0.96) tetapi recall lebih rendah (0.82), menunjukkan bahwa model ini lebih akurat daripada Random Forest dalam mendeteksi \"Spam\" tetapi masih tidak lebih baik daripada Logistic Regression.<br>\n    Akurasi keseluruhan adalah 0.90, menunjukkan peningkatan dari Random Forest tetapi masih lebih rendah daripada Logistic Regression.\n  </p>\n  \n  <h2 style=\"color: #1E88E5; font-size: 1.5em; margin-bottom: 10px;\">\n    Analisis\n  </h2>\n  <p>\n    Gradient Boosted Trees dapat menangkap pola non-linear lebih baik dibandingkan Logistic Regression karena pendekatannya dalam meningkatkan kesalahan dari model sebelumnya secara iteratif.<br>\n    Namun, dalam kasus ini, sepertinya Gradient Boosted Trees masih memiliki kesulitan dalam menangkap semua pola untuk \"Spam\", kemungkinan karena overfitting atau kurangnya kompleksitas data yang dapat dimanfaatkan sepenuhnya oleh model ini.\n  </p>\n  \n  <h2 style=\"color: #1E88E5; font-size: 1.5em; margin-bottom: 10px;\">\n    Alasan Performa\n  </h2>\n  <p>\n    Meskipun dapat memodelkan hubungan non-linear, Gradient Boosted Trees mungkin tidak selalu lebih baik jika fitur tidak memberikan informasi yang cukup untuk membedakan kelas dengan baik.<br>\n    Kemungkinan terjadi overfitting pada training data, yang menyebabkan performa model menurun ketika diterapkan pada data uji.\n  </p>\n\n</div>\n\n</body>\n</html>\n","metadata":{}},{"cell_type":"markdown","source":"### Model Comparison","metadata":{}},{"cell_type":"code","source":"# Bandingkan hasil\nprint(\"Model Comparison:\")\nprint(f\"Logistic Regression Accuracy: {lr_accuracy:.2f}\")\nprint(f\"Random Forest Accuracy: {rf_accuracy:.2f}\")\nprint(f\"Gradient Boosted Trees Accuracy: {gbt_accuracy:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-23T04:17:28.967038Z","iopub.execute_input":"2024-10-23T04:17:28.967370Z","iopub.status.idle":"2024-10-23T04:17:28.973042Z","shell.execute_reply.started":"2024-10-23T04:17:28.967336Z","shell.execute_reply":"2024-10-23T04:17:28.972043Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Menyimpan akurasi masing-masing model\nmodel_names = ['Logistic Regression', 'Random Forest', 'Gradient Boosted Trees']\nmodel_accuracies = [lr_accuracy, rf_accuracy, gbt_accuracy]\n\n# Membuat bar chart\nplt.figure(figsize=(8, 6))\nplt.barh(model_names, model_accuracies, color=['blue', 'green', 'orange'])\n\n# Menambahkan detail pada plot\nplt.xlabel('Accuracy')\nplt.title('Model Comparison: Accuracy of Logistic Regression, Random Forest, and GBT')\nplt.xlim(0, 1)  # Membatasi nilai akurasi antara 0 dan 1\nfor index, value in enumerate(model_accuracies):\n    plt.text(value + 0.01, index, f\"{value:.2f}\", va='center')\n\n# Menampilkan plot\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T04:17:28.974454Z","iopub.execute_input":"2024-10-23T04:17:28.975247Z","iopub.status.idle":"2024-10-23T04:17:29.162321Z","shell.execute_reply.started":"2024-10-23T04:17:28.975203Z","shell.execute_reply":"2024-10-23T04:17:29.161413Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!DOCTYPE html>\n<html>\n<head>\n  <link href=\"https://fonts.googleapis.com/css2?family=Poppins:wght@400;700&display=swap\" rel=\"stylesheet\">\n</head>\n<body style=\"font-family: 'Poppins', sans-serif; background-color: #f7f9fc; color: #333; margin: 20px; line-height: 1.6;\">\n\n<div style=\"width: 80%; margin: 0 auto; padding: 20px; background-color: #fff; border-radius: 8px; box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);\">\n  \n  <h2 style=\"color: #1E88E5; font-size: 1.5em; margin-bottom: 10px;\">\n    Kesimpulan\n  </h2>\n  <p>\n    Logistic Regression menghasilkan performa terbaik karena kemungkinan data yang digunakan memiliki karakteristik linear yang jelas, dan model ini dapat mengklasifikasikan dengan akurat untuk kedua kelas.<br><br>\n    Random Forest memiliki masalah dalam mendeteksi \"Spam\" karena mungkin kurang optimal dalam pengaturan parameternya atau data memiliki noise yang mengganggu.<br><br>\n    Gradient Boosted Trees menunjukkan peningkatan dibandingkan Random Forest tetapi tidak lebih baik dari Logistic Regression, mungkin karena data tidak sepenuhnya memerlukan pendekatan non-linear yang kompleks.\n  </p>\n\n</div>\n\n</body>\n</html>\n","metadata":{}}]}